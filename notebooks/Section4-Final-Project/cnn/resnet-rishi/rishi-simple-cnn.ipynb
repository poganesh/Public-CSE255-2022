{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4817ab-7871-4812-9db4-e9f747a6553d",
   "metadata": {},
   "source": [
    "# A simple CNN for Poverty dataset\n",
    "\n",
    "In this HW, you will be working on implementing models / algorithms for performing classification on the [WILDS Poverty Map](https://wilds.stanford.edu/datasets/#povertymap) dataset.\n",
    "To help you get started with this, we will build a simple CNN for binary classification on the given dataset. In this notebook, I'll be covering the following things:\n",
    "1. Loading data\n",
    "2. Designing a CNN\n",
    "3. Training the model\n",
    "4. Evaluating the model\n",
    "\n",
    "**The code given here assumes you have access to a NVIDIA GPU and have cuda installed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec599911-526c-4d29-9675-5d7332189d91",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22847361-03e1-4783-a1e9-6c448c57de7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitwiz/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics.functional as metrics\n",
    "from resnet import *\n",
    "import ntpath\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5f894-1a98-4b3f-bdd5-7faef1aed6f5",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "\n",
    "The dataset consists of satellite images (8 channels) across 23 countries and their corresponding wealth index. The wealth index has been thresholded to provide binary labels indicating wealthy (1)/poor(0). You can read more about the dataset and it's characteristics [here](https://www.nature.com/articles/s41467-020-16185-w).\n",
    "\n",
    "### Dataset format\n",
    "The dataset is stored as numpy dumps `(.npz)` format and are available in `/datasets/cs255-sp22-a00-public/poverty/anon_images` on datahub. We have partitioned the data into train and test sets. The different partitions and mapping from file to labels are provided as csv files.\n",
    "The partitions are decided by:\n",
    "- `train.csv` Containes metadata of the training split\n",
    "- `random_test_reduct.csv` Test images sampled from all countries included in the trainset\n",
    "- `country_test_reduct.csv` Test images sampled from countries NOT in the trainset \n",
    "\n",
    "We provide 2 test sets as we want you to work on 2 different problems. The `random_test_reduct` partition is for in-domain testing and the `country_test_reduct` partition is meant for out-of-domain testing. The former problem is the easier one to start and the focus of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346eba6d-f8c6-4e37-8c83-d80639061915",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/home/bitwiz/codeden/ta/cse255/Poverty_Analysis/public_tables/'\n",
    "train_csv_path = os.path.join(csv_path, 'train.csv')\n",
    "test_csv_path = os.path.join(csv_path, 'random_test_reduct.csv')\n",
    "image_path = '/home/bitwiz/codeden/data/wilds/anon_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492a8c02-b278-4da0-9188-05b8172943a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>urban</th>\n",
       "      <th>label</th>\n",
       "      <th>nl_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image14517.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.019361</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.086633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image7407.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.143002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image390.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.056769</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>15.228898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image7980.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.454064</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>11.082343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>image13397.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.708446</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>12.646744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  country  wealthpooled  urban  label    nl_mean\n",
       "0  image14517.npz        6     -1.019361  False      0  -0.086633\n",
       "2   image7407.npz        6     -1.143002  False      0  -0.141589\n",
       "3    image390.npz        6      1.056769   True      0  15.228898\n",
       "4   image7980.npz        6      1.454064   True      1  11.082343\n",
       "5  image13397.npz        6      1.708446   True      1  12.646744"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv_path, index_col = 0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ea148-0a32-460b-9aeb-887532a6ac8e",
   "metadata": {},
   "source": [
    "### Dataloading pipeline\n",
    "\n",
    "In order to work with this dataset we need to convert the data to a format compatible with PyTorch. The PyTorch API exposes a set of utility functions at `torch.utils.data`. The 2 important classes you need to know about are `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`. The `Dataset` class implements an iterable dataset which allows you to step through your data with indices. The `DataLoader` class provides the functionality to load the data in batches and feed it to the GPU/CPU during training/testing.\n",
    "\n",
    "For our Poverty dataset, we will implement a custom `Dataset` class that will load the csv file and appropriately configure the data. The `Dataset` class needs to implement 2 methods: `__len__` and `__getitem__` as a bare minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb321a4-7735-4fe8-bd71-f824e5b2644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildsDataset(Dataset):\n",
    "    '''\n",
    "    Custom Dataset class for wilds poverty dataset\n",
    "    input:\n",
    "        image_paths: csv path to split\n",
    "        idx_to_class: a dictionary mapping index of datapoint to it's label\n",
    "    '''\n",
    "    def __init__(self, image_paths, idx_to_class = None, transform = None):\n",
    "        super().__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.idx_to_class = idx_to_class\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image = np.load(self.image_paths[idx])\n",
    "        image = image.f.x\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.idx_to_class:\n",
    "            index = self.image_paths[idx].split('/')[-1]\n",
    "            label = self.idx_to_class[index]\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f84a5-2527-494a-935d-767a88b7e3d3",
   "metadata": {},
   "source": [
    "#### Test the dataset\n",
    "\n",
    "Our WildsDataset takes as input 2 arguments. First a list of image paths, 2nd a mapping from images to labels.\n",
    "We will generate these image paths and the mapping from `train.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a519eb46-fff0-419b-8c6a-042c6be97002",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows = train_df.loc[:, ['filename', 'label']].to_dict(orient='records')\n",
    "label_map = {x['filename']: x['label'] for x in csv_rows}\n",
    "\n",
    "train_image_paths = [os.path.join(image_path, csv_rows[index]['filename']) for index in range(len(train_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f340263f-2d25-404e-8b56-9f17ebecba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 224, 224) 0\n"
     ]
    }
   ],
   "source": [
    "ds = WildsDataset(train_image_paths, label_map)\n",
    "x, y = ds[0]\n",
    "print(x.shape, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272b24c-bc14-4e4c-98a2-9b53524f090e",
   "metadata": {},
   "source": [
    "### Convert `Dataset` to `DataLoader`\n",
    "\n",
    "Now that we have the dataset class implemented, we will wrap it in the `DataLoader` class for us to generate batches of images to train the mode on.\n",
    "In order to make life easier, we use a package called `pytorch-lightning` which abstracts away all the boiler plate code of PyTorch. You do not need to know much about this package to use it. We will walkthrough the relevant functions in this notebook.\n",
    "\n",
    "We will implement a `LightningDataModule` which provides APIs to fetch the required DataLoader. Below is the template for creating a dataModule. We will define the `_create` function next which will initialize the train, val and test splits of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410e7e13-0734-4e03-92b7-2fd7a032a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildsDM(pl.LightningDataModule):\n",
    "    def __init__(self, csv_path, image_path, test_csv_path, batch_size = 256, train_val_split_ratio = 0.9, test = True):\n",
    "        super().__init__()\n",
    "        self.csv_path = csv_path\n",
    "        self.image_path = image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.train_val_split_ratio = train_val_split_ratio\n",
    "        self.test_csv_path = test_csv_path\n",
    "        \n",
    "        if test:\n",
    "            self._create()\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        self._create()\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size = self.batch_size, shuffle = True, num_workers = 8)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size = self.batch_size, shuffle = False, num_workers = 8)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size = self.batch_size, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87500479-a411-4040-be4c-473bf573cb45",
   "metadata": {},
   "source": [
    "We will now implement the `_create` function. The function essentially is going to implement the logic we wrote in `Test the dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f7156c-81ac-4bf1-8b67-eb5c2d520c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildsDM(WildsDM):\n",
    "    def _create(self):\n",
    "        csv_df = pd.read_csv(self.csv_path, index_col = 0)\n",
    "        csv_rows = train_df.loc[:, ['filename', 'label']].to_dict(orient='records')\n",
    "        \n",
    "        train_indices, val_indices = train_test_split(range(len(csv_rows)), train_size = self.train_val_split_ratio)\n",
    "        \n",
    "        train_image_paths = [os.path.join(self.image_path, csv_rows[index]['filename']) for index in train_indices]\n",
    "        val_image_paths = [os.path.join(self.image_path, csv_rows[index]['filename']) for index in val_indices]\n",
    "        label_map = {x['filename']: x['label'] for x in csv_rows}\n",
    "        \n",
    "        self.train_set = WildsDataset(train_image_paths, label_map)\n",
    "        self.val_set = WildsDataset(val_image_paths, label_map)\n",
    "        \n",
    "        test_df = pd.read_csv(self.test_csv_path, index_col = 0)\n",
    "        self.test_image_paths = [os.path.join(self.image_path, row['filename']) for index,row in test_df.iterrows()]\n",
    "        self.test_set = WildsDataset(self.test_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04cf7f-4be5-45ad-b3d5-08b79b7d4db6",
   "metadata": {},
   "source": [
    "#### Test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252479b-4eeb-4938-a049-d8a4365e8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = WildsDM(train_csv_path, image_path, test_csv_path)\n",
    "\n",
    "for batch in dm.train_dataloader():\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "for batch in dm.val_dataloader():\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "    \n",
    "for batch in dm.test_dataloader():\n",
    "    x = batch\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e015b64-4a25-40ee-ad65-39a7c9d18067",
   "metadata": {},
   "source": [
    "## 2. Model Architecture and Loss\n",
    "\n",
    "Next we will look at defining a CNN architecture and setting up the loss functions and optimizer to train the CNN. Again we will make use of `pytorch-lightning` to abstract the boilerplate code for PyTorch training.\n",
    "\n",
    "The lightning framework exposes a `LightningModule` which instantiates functions for training, validation and testing.\n",
    "First we instantiate the model, loss function and define the forward pass for the model. For our model, we will be using a ResNet-18 architecture. ResNet is a residual CNN architecture that was introduced in this [paper](https://arxiv.org/pdf/1512.03385.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f7cf53-64bb-4c72-bae4-597a0b090689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_module(pl.LightningModule):\n",
    "    def __init__(self, lr = 0.001, weight_decay = 1e-4):\n",
    "        super().__init__()\n",
    "        self.model = ResNet18(num_classes = 2, num_channels = 8)\n",
    "        self.lr = lr\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbede704-beab-413d-a835-649dd5a6b633",
   "metadata": {},
   "source": [
    "Next we define the operations we will perform during each step of training, validation and testing. We will do this through the hooks provided by `LightningModule`. The `LightningModule` provides 3 functions: `training_step`, `validation_step` and `test_step` inside which you define the operations that happen one batch of data. Internally `LightningModule` loads batches of data from the `dataModule` and for each batch,\n",
    "calls the appropriate step function depending on whether the model is being trained or evaluated. The step functions take as input a single batch and expects you to return the loss value for backpropogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e7c6ff-205c-4dc6-9635-8769e926edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_module(baseline_module):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # process a single batch\n",
    "        loss, acc = self.single_step(batch)\n",
    "        \n",
    "        #log the values and display them on the progress bar\n",
    "        self.log('tloss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        self.log('tacc', acc, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.single_step(batch)\n",
    "        \n",
    "        self.log('vloss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        self.log('vacc', acc, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "    \n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         loss = self.single_step(test = True)\n",
    "        \n",
    "#         self.log('test_loss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd844039-21f9-4c73-a942-c2aeb67f19ad",
   "metadata": {},
   "source": [
    "### Forward pass (Process a single batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fddf9bab-7b04-482e-a737-1e3160b68357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_module(baseline_module):\n",
    "    def single_step(self, batch, test = False):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        loss = self.loss(y_hat, y)\n",
    "        _, preds = torch.max(y_hat, dim = 1)\n",
    "        \n",
    "        acc = metrics.accuracy(preds, y)\n",
    "        \n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50715f-4c16-4ae6-be04-6041a481bbec",
   "metadata": {},
   "source": [
    "Now that we have the model and have implemented the forward passes, we need to configure the optimizer for training. The `LightningModule` takes care of backpropogation and moving the data to GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d206034e-aa41-4b50-b7af-75b93f8943fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_module(baseline_module):\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.weight_decay, momentum=0.9)\n",
    "        \n",
    "        return {'optimizer': optim}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535643cf-fd5d-402c-b2fb-337c8bc4586e",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "We have implemented the data pipeline and the model training pipeline. The last step is to start training. `pytorch_lightning` provides a `Trainer` class which wraps the model and data module into an end-to-end pipeline and begins training. We will also add some callbacks to checkpoint and save our best model along with it's hyperparameters and train val logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8230c3bf-f2f6-49d8-b0a9-ff864dcde73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(save_dir = './logs', name = 'resnet', version = 'test')\n",
    "ckpt = pl.callbacks.ModelCheckpoint(dirpath = './checkpoints', monitor = 'vloss', mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc798db8-cc32-48a6-a165-08538b4c9c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = baseline_module()\n",
    "dm = WildsDM(train_csv_path, image_path, test_csv_path)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus = 1, accelerator = 'gpu', max_epochs = 5, precision = 16,\n",
    "    strategy = 'dp', logger = [csv_logger], callbacks = [ckpt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fefbc3c1-84bd-4269-a899-24bdbb7772b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitwiz/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/bitwiz/codeden/ta/cse255/rishi/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | ResNet18         | 11.2 M\n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.386    Total estimated model params size (MB)\n",
      "/home/bitwiz/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/pytorch_lightning/loggers/csv_logs.py:57: UserWarning: Experiment logs directory ./logs/resnet/test exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bitwiz/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 40/45 [00:14<00:01,  2.85it/s, loss=0.691, v_num=test]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████████████████████████▌                                                                                                      | 1/5 [00:00<00:00,  8.10it/s]\u001b[A\n",
      "Epoch 0:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 41/45 [00:16<00:01,  2.46it/s, loss=0.691, v_num=test]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████████████████████████████████▏                                                                            | 2/5 [00:00<00:00,  6.59it/s]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 42/45 [00:16<00:01,  2.50it/s, loss=0.691, v_num=test]\u001b[A\n",
      "Validation DataLoader 0:  60%|████████████████████████████████████████████████████████████████████████████▊                                                   | 3/5 [00:00<00:00,  6.80it/s]\u001b[A\n",
      "Epoch 0:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 43/45 [00:16<00:00,  2.54it/s, loss=0.691, v_num=test]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 4/5 [00:00<00:00,  6.58it/s]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 44/45 [00:17<00:00,  2.57it/s, loss=0.691, v_num=test]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:17<00:00,  2.57it/s, loss=0.691, v_num=test, vloss=0.691, vacc=0.544]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████████████████████▍       | 40/45 [00:12<00:01,  3.31it/s, loss=0.689, v_num=test, vloss=0.691, vacc=0.544, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████████████████████████▌                                                                                                      | 1/5 [00:00<00:00,  8.16it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████▉      | 41/45 [00:14<00:01,  2.79it/s, loss=0.689, v_num=test, vloss=0.691, vacc=0.544, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████████████████████████████████▏                                                                            | 2/5 [00:00<00:00,  6.24it/s]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████████████████████▍    | 42/45 [00:14<00:01,  2.82it/s, loss=0.689, v_num=test, vloss=0.691, vacc=0.544, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Validation DataLoader 0:  60%|████████████████████████████████████████████████████████████████████████████▊                                                   | 3/5 [00:00<00:00,  6.39it/s]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████████████████████▉   | 43/45 [00:15<00:00,  2.86it/s, loss=0.689, v_num=test, vloss=0.691, vacc=0.544, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 4/5 [00:00<00:00,  6.50it/s]\u001b[A\n",
      "Epoch 1:  98%|██████████████████████████████████████████████████████████████████▍ | 44/45 [00:15<00:00,  2.90it/s, loss=0.689, v_num=test, vloss=0.691, vacc=0.544, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.93it/s, loss=0.689, v_num=test, vloss=0.692, vacc=0.540, tloss=0.723, tacc=0.539]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████████████████████▍       | 40/45 [00:12<00:01,  3.29it/s, loss=0.691, v_num=test, vloss=0.692, vacc=0.540, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████████████████████████▌                                                                                                      | 1/5 [00:00<00:00,  9.32it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████▉      | 41/45 [00:14<00:01,  2.78it/s, loss=0.691, v_num=test, vloss=0.692, vacc=0.540, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████████████████████████████████▏                                                                            | 2/5 [00:00<00:00,  7.58it/s]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████████████████████▍    | 42/45 [00:14<00:01,  2.82it/s, loss=0.691, v_num=test, vloss=0.692, vacc=0.540, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Validation DataLoader 0:  60%|████████████████████████████████████████████████████████████████████████████▊                                                   | 3/5 [00:00<00:00,  6.86it/s]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████████████████████▉   | 43/45 [00:15<00:00,  2.86it/s, loss=0.691, v_num=test, vloss=0.692, vacc=0.540, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 4/5 [00:00<00:00,  6.94it/s]\u001b[A\n",
      "Epoch 2:  98%|██████████████████████████████████████████████████████████████████▍ | 44/45 [00:15<00:00,  2.90it/s, loss=0.691, v_num=test, vloss=0.692, vacc=0.540, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.61it/s]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.93it/s, loss=0.691, v_num=test, vloss=0.702, vacc=0.545, tloss=0.690, tacc=0.547]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████████████████████████████████████▍       | 40/45 [00:11<00:01,  3.36it/s, loss=0.688, v_num=test, vloss=0.702, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████████████████████████▌                                                                                                      | 1/5 [00:00<00:00,  8.76it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████▉      | 41/45 [00:14<00:01,  2.83it/s, loss=0.688, v_num=test, vloss=0.702, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████████████████████████████████▏                                                                            | 2/5 [00:00<00:00,  7.49it/s]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████████████████████████████████████▍    | 42/45 [00:14<00:01,  2.87it/s, loss=0.688, v_num=test, vloss=0.702, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Validation DataLoader 0:  60%|████████████████████████████████████████████████████████████████████████████▊                                                   | 3/5 [00:00<00:00,  6.88it/s]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████████████████████▉   | 43/45 [00:14<00:00,  2.90it/s, loss=0.688, v_num=test, vloss=0.702, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 4/5 [00:00<00:00,  6.64it/s]\u001b[A\n",
      "Epoch 3:  98%|██████████████████████████████████████████████████████████████████▍ | 44/45 [00:14<00:00,  2.94it/s, loss=0.688, v_num=test, vloss=0.702, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.02it/s]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.97it/s, loss=0.688, v_num=test, vloss=0.689, vacc=0.545, tloss=0.686, tacc=0.553]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████████████████████████████████████▍       | 40/45 [00:12<00:01,  3.32it/s, loss=0.683, v_num=test, vloss=0.689, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                                        | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|█████████████████████████▌                                                                                                      | 1/5 [00:00<00:00,  8.80it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████████████████████████████████████████████████████████▉      | 41/45 [00:14<00:01,  2.80it/s, loss=0.683, v_num=test, vloss=0.689, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████████████████████████████████████████████████▏                                                                            | 2/5 [00:00<00:00,  6.87it/s]\u001b[A\n",
      "Epoch 4:  93%|███████████████████████████████████████████████████████████████▍    | 42/45 [00:14<00:01,  2.84it/s, loss=0.683, v_num=test, vloss=0.689, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Validation DataLoader 0:  60%|████████████████████████████████████████████████████████████████████████████▊                                                   | 3/5 [00:00<00:00,  6.63it/s]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████████████████████████████████████▉   | 43/45 [00:14<00:00,  2.88it/s, loss=0.683, v_num=test, vloss=0.689, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 4/5 [00:00<00:00,  6.85it/s]\u001b[A\n",
      "Epoch 4:  98%|██████████████████████████████████████████████████████████████████▍ | 44/45 [00:15<00:00,  2.92it/s, loss=0.683, v_num=test, vloss=0.689, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.41it/s]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.95it/s, loss=0.683, v_num=test, vloss=0.710, vacc=0.545, tloss=0.685, tacc=0.559]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:15<00:00,  2.95it/s, loss=0.683, v_num=test, vloss=0.710, vacc=0.545, tloss=0.685, tacc=0.556]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule = dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885da16-0eff-4061-836c-42b2cef04a3c",
   "metadata": {},
   "source": [
    "### Loading a pre-trained model\n",
    "\n",
    "`LightningModule` also provides APIs to easily load pre-trained models and resume training from a checkpoint.\n",
    "For us to load a pre-trained model, the model's module/class needs to be imported in the namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f4aa9-db77-4717-a744-a7ef068fe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = ckpt.best_model_path\n",
    "\n",
    "# Any parameters you want to change while loading the model can be passed along as well\n",
    "pre_trained = baseline_module.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8feba9-d2ab-4f6d-be3a-656e6d5b382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pre_trained)\n",
    "del(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d9ce2-81d7-44b0-995a-7c7c3d416d9c",
   "metadata": {},
   "source": [
    "## 4. Testing\n",
    "\n",
    "Now that we have trained our model, we will write the code to feed data from our test dataloader and get predictions for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56699f36-89d4-48f9-a564-e07659ae92ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 23.69 GiB total capacity; 21.03 GiB already allocated; 57.44 MiB free; 21.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 12\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39msoftmax(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m preds \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mbaseline_module.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/resnet.py:220\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x, with_feats)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, with_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_feats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/resnet.py:210\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x, with_feats)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, with_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(feats)\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/resnet.py:196\u001b[0m, in \u001b[0;36mResNet.get_feats\u001b[0;34m(self, x, layer)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 196\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/resnet.py:52\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[1;32m     55\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codeden/ta/cse255/rishi/255/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 23.69 GiB total capacity; 21.03 GiB already allocated; 57.44 MiB free; 21.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "ckpt_path = ckpt.best_model_path\n",
    "best_model = baseline_module.load_from_checkpoint(ckpt_path).to('cuda')\n",
    "test_image_names = list(map(lambda x: ntpath.basename(x), dm.test_image_paths))\n",
    "\n",
    "name_labels_nn = collections.defaultdict(list)\n",
    "name_scores_nn = collections.defaultdict(list)\n",
    "\n",
    "for batch_idx, batch in enumerate(dm.test_dataloader()):\n",
    "    start_index = batch_idx * dm.batch_size\n",
    "    x = batch\n",
    "    x = x.cuda()\n",
    "    y_hat = best_model(x)\n",
    "    y_hat = y_hat.softmax(dim = 1)\n",
    "    preds = y_hat.argmax(dim=1)\n",
    "    \n",
    "    for pred_index, pred in enumerate(preds):\n",
    "        name_labels_nn[test_image_names[start_index + pred_index]].append(pred.item())\n",
    "            \n",
    "    for score_index, score in enumerate(y_hat):\n",
    "        name_scores_nn[test_image_names[start_index + score_index]].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a22137-8452-4c64-ac5b-d2e14b419f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_csv_path, index_col = 0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6074b09-c94c-4d4e-8278-7e00332b6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(threshold=0.6, use_score=True):\n",
    "    name_preds = []\n",
    "    for index, row in test_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        \n",
    "        score = name_scores_nn[filename]\n",
    "        curr_pred = name_labels_nn[filename][0]\n",
    "        # print(curr_pred, score)\n",
    "        if score[curr_pred] > threshold:\n",
    "            pred = curr_pred\n",
    "        else:\n",
    "            pred = -1                \n",
    "        \n",
    "        name_preds.append([filename, pred, curr_pred])\n",
    "        \n",
    "    preds_df = pd.DataFrame(name_preds, columns=['filename', 'pred_with_abstention', 'pred_wo_abstention'])\n",
    "    \n",
    "    return preds_df\n",
    "        \n",
    "preds_df = get_preds()\n",
    "outputs_df = test_csv_df[['filename', 'urban']].merge(preds_df, on='filename')\n",
    "outputs_df = outputs_df.astype({'urban': int})\n",
    "outputs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d184d63-7ef3-4f86-9027-8112135ecdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "255",
   "language": "python",
   "name": "255"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
